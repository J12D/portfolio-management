for (i in seq(from = 0, to = risk.premium.up, by = risk.increment)) {
dvec <- mu * i # This moves the solution along the EF
sol <- solve.QP(c, dvec = dvec, Amat = Amat, bvec = bvec, meq = meq)
eff[loop, "Std.Dev"] <- sqrt(sum(sol$solution * colSums((c * sol$solution))))
eff[loop, "Exp.Return"] <- as.numeric(sol$solution %*% mu)
eff[loop, "sharpe"] <- eff[loop,"Exp.Return"] / eff[loop,"Std.Dev"]
eff[loop, 1:n] <- sol$solution
loop <- loop + 1
}
eff <- as.data.frame(eff)
eff <- eff[eff$sharpe == max(eff$sharpe), 1:n]
rownames(eff) <- NULL
eff[1,]
}
}
eff_portfolio(mean_returns(), cov_returns(), T, 3, 0.01, NULL) %>% performance_plot
eff_portfolio(mean_returns(), cov_returns(), F, 3, 0.01, NULL) %>% performance_plot
eff_portfolio(mean_returns(shrink=0.5), cov_returns(), T, 3, 0.01, NULL) %>% performance_plot
eff_portfolio(mean_returns(shrink=0.5), cov_returns(), T, 3, 0.001, NULL) %>% performance_plot
eff_portfolio(mean_returns(shrink=0.9), cov_returns(), T, 3, 0.01, 0.7) %>% performance_plot
library(reshape2)
library(ggplot2)
library(corrplot)
library(tawny)
source("0-helper.R")
source("1-data.R")
source("3-analysis2.R")
## ---- Mean ----------
mean_returns <- function(shrink = 0, annualize = 252) {
function(returns) {
r <- returns %>% apply(2, mean) * annualize
r * (1 - shrink) + Reduce(mean, r) * shrink
}
}
## ---- Covariance -----------
hayashi_yoshida <- function(ts_fixing_pre, ts_fixing_post) {
ts_fixing_post %>% lag %>% head
aligned <- merge.xts(ts_fixing_pre,ts_fixing_post)
aligned %<>% na.omit
cov(aligned[,1],aligned[,2])
}
# add a vector at a given position to a square matrix, both on row and on column (for hayashi)
# 0 0 0                   0 1 0
# 0 0 0 + {1,2,3} @ 2 ==> 1 4 3
# 0 0 0                   0 3 0
addCross <- function(m,vec,pos) {
l <- dim(m)[1]
row <- c(rep(0, (pos - 1) * l), vec, rep(0, (l - pos) * l)) %>% matrix(nrow = l, byrow = T)
col <- c(rep(0, (pos - 1) * l), vec, rep(0, (l - pos) * l)) %>% matrix(ncol = l)
m + row + col
}
cov_returns <- function(lag_adjustment = F, shrink = F, annualize = 252) {
function(returns) {
cov_func <- if (shrink) cov.shrink else cov
c <- cov_func(returns)
if (lag_adjustment != F) {
hayashi_results <- returns[,-lag_adjustment] %>%
apply(2, function(x) hayashi_yoshida(returns[,lag_adjustment],x))
adjustment <- c(hayashi_results[1:(lag_adjustment - 1)],
0,
hayashi_results[(lag_adjustment:length(hayashi_results))])
# add adjustment onto covariance matrix
c %<>% addCross(adjustment,3)
}
c * annualize
}
}
# calculate correlation from adjusted covariance matrix (not perfect)
adjusted_cor <- function(adjusted_cov, returns) {
standard_devs <- returns %>% apply(2,sd)
adjusted_cov / outer(standard_devs,standard_devs)
}
# Compare correlation with and without Hayashi-Yoshida adjustment
cor(returns) %>% corrplot
returns %>% (cov_returns(lag_adjustment = 3)) %>% adjusted_cor(returns) %>% corrplot
## ---- Models ------------------------
mean_variance_ibase <- function(mu, information_matrix) {
(information_matrix %*% mu)/as.numeric(rep(1,length(mu)) %*% information_matrix %*% mu)
}
mean_variance_base <- function(mu, sigma) {
mean_variance_ibase(mu, sigma %>% solve)
}
mean_variance_optimal <- function(mu, information_matrix, phi) {
n <- length(mu)
a3 <- sum(information_matrix %*% ones(n)) #1'S^(-1)1
weights <- (information_matrix %*% ones(n)) / a3 +
1 / phi * (
a3 * information_matrix %*% mu -
sum(information_matrix %*% mu) * information_matrix %*% ones(n)
) / a3
weights
}
min_variance <- function(mean = mean_returns(), cov = cov_returns()) {
function(returns) {
mu <- returns %>% mean
c <- returns %>% cov
mean_variance_optimal(mu, c %>% solve, Inf) %>% t
}
}
max_sharpe <- function(mean = mean_returns(), cov = cov_returns()) {
function(returns) {
mu <- returns %>% mean
c <- returns %>% cov
mean_variance_base(mu, c) %>% t
}
}
fixed_weights <- function(weights) {
function(returns) {
t(weights)
}
}
## ---- base-wrapper --------------------------
# select an expanding window of returns, starting end of 2012 and feed it into the model
months_calibration <- index(returns["2012/"])[endpoints(returns["2012/"],"months")]
evaluate_model <- function(model, lookback = "1 year", subset = "2012/", period = "months") {
vars <- index(returns[subset])[endpoints(returns[subset], period)] %>%
lapply(function(date) returns[paste0("/", date)]) %>%
lapply(function(returns) {
date <- index(returns) %>% last %>% as.Date
returns <- returns %>% xts::last(lookback)
val <- model(returns)
print(val)
xts(val, date)
}) %>%
Reduce(rbind,.)
vars
}
# min_variance() %>% evaluate_model %>% plotXTS
# Max Sharpe with shrunken means
# max_sharpe(mean = mean_returns(shrink = 1)) %>% evaluate_model %>% plotXTS
# Min Variance with hayashi yoshida adjustment
# w <- min_variance(cov = cov_returns(lag_adjustment = 3)) %>% evaluate_model
# w %>% plotXTS + ylim(c(-1,1.5))
## ---- performance-calculation --------------------------
drop_first <- function(x) {
x[-1,]
}
drop_last <- function(x) {
x[-dim(x)[1],]
}
portfolio_return <- function(weights, subset = "2012/", period = "months") {
dates <- index(returns[subset])[endpoints(returns[subset], period)]
# returns for decision months
periodical_returns <- lag(assets[dates],-1) / assets[dates] - 1
portfolio_returns <- rowSums(periodical_returns * weights, na.rm = T) %>%
xts(index(weights)) %>%
(function(x) cumprod(1 + x))
vals <- apply(assets[subset], 1, function(x) x/as.numeric(assets[subset][1,])) %>% t
my_asset_returns <- xts(vals, index(assets[subset]))
#merge.xts(portfolio_returns, my_asset_returns) %>% na.omit %>% plotXTS
weight_development <- function(initial_weights, asset_evolution, amt = 1) {
units <- amt / as.numeric(asset_evolution[1,]) * as.numeric(initial_weights)
vals <- apply(asset_evolution, 1, function(x) x * units) %>% t
xts(coredata(vals),index(asset_evolution))
}
relative_weights <- function(x) {
x/rowSums(x)
}
# first month
# weight_development(weights[1,], assets['2012-01-31/2012-02-29'], 100) %>% rowSums
# weight_development(weights[2,], assets['2012-02-29/2012-03-30'], 101.42630) %>% rowSums
periods <- paste0(dates[1:(length(index(dates)) - 1)], "/", dates[2:length(index(dates))])
period_assets <- periods %>% sapply(function(x)assets[x] %>% drop_first)
p <- vector(mode = "list", length = dim(weights)[1])
for (i in 1:dim(weights)[1]) {
p[[i]] <- list(weights = weights[i], assets = period_assets[[i]])
}
pf <- Reduce(function(carry, period_slice) {
if (is.null(carry)) {
value <- 100
} else {
value <- rowSums(carry) %>% last
}
assets <- period_slice$assets
weights <- period_slice$weights
res <- weight_development(weights, assets, value)
if (!is.null(carry)) {
res <- rbind(carry,res)
}
res
}, p, NULL)
pf
}
rowSums.xts <- function(x) {
xts(rowSums(x), index(x))
}
zero_killer <- function(x) {
pf_idx <- which(x < 0) %>% first
if(!is.na(pf_idx)) {
x[pf_idx:dim(x)[1]] <- 0
}
x
}
## ---- Pipelines ------------------
performance_plot <- function(model) {
model %>%
evaluate_model %>%
drop_last %>%
portfolio_return %>%
rowSums.xts %>%
zero_killer %>%
plotXTS(size = 1)
}
min_variance(cov = cov_returns(shrink = T, lag_adjustment = 3)) %>% performance_plot
eff_portfolio(mean_returns(shrink=0.1), cov_returns(lag_adjustment = 3), T, 3, 0.01, NULL) %>% performance_plot
eff_portfolio(mean_returns(shrink=0.1), cov_returns(), T, 3, 0.01, NULL) %>% performance_plot
#http://economistatlarge.com/portfolio-theory/r-optimized-portfolio
library(quadprog)
eff_portfolio <- function(mean = mean_returns(), cov = cov_returns(),
short = F, risk.premium.up = 3, risk.increment = 0.1,
max.allocation = NULL) {
function(returns) {
mu <- returns %>% mean
c <- returns %>% cov
n <- ncol(c)
# Create Amat & bvec assuming only equality constraint, short-selling allowed, no allocation constraints
Amat <- matrix(1, nrow = n)
bvec <- 1
meq <- 1
# Modify Amat & bvec if short-selling not allowed
if (short) {
Amat <- cbind(1, diag(n))
bvec <- c(bvec, rep(0, n))
}
# Modify Amat & bvec for max allocation constraint
if (!is.null(max.allocation)) {
if (max.allocation > 1 | max.allocation < 0) {
stop("max.allocation must be greater than 0 and less than 1")
}
if (max.allocation * n < 1) {
stop("Need to set max.allocation higher; not enough assets to add to 1")
}
Amat <- cbind(Amat, -diag(n))
bvec <- c(bvec, rep(-max.allocation, n))
}
# Calculate #loops
loops <- risk.premium.up / risk.increment + 1
loop <- 1
# Initialize a matrix to contain allocation and statistics
eff <- matrix(nrow = loops, ncol = n+3)
# Now I need to give the matrix column names
colnames(eff) <- c(colnames(returns), "Std.Dev", "Exp.Return", "sharpe")
# Loop through the quadratic program solver
for (i in seq(from = 0, to = risk.premium.up, by = risk.increment)) {
dvec <- mu * i # This moves the solution along the EF
sol <- solve.QP(c, dvec = dvec, Amat = Amat, bvec = bvec, meq = meq)
eff[loop, "Std.Dev"] <- sqrt(sum(sol$solution * colSums((c * sol$solution))))
eff[loop, "Exp.Return"] <- as.numeric(sol$solution %*% mu)
eff[loop, "sharpe"] <- eff[loop,"Exp.Return"] / eff[loop,"Std.Dev"]
eff[loop, 1:n] <- sol$solution
loop <- loop + 1
}
eff <- as.data.frame(eff)
eff <- eff[eff$sharpe == max(eff$sharpe), 1:n]
rownames(eff) <- NULL
eff[1,]
}
}
eff_portfolio(mean_returns(shrink=0.1), cov_returns(), T, 3, 0.01, NULL) %>% performance_plot
eff_portfolio(mean_returns(shrink=0.1), cov_returns(lag_adjustment = 3), T, 3, 0.01, NULL) %>% performance_plot
eff_portfolio(mean_returns(shrink=0.1), cov_returns(shrink = 3), T, 3, 0.01, NULL) %>% performance_plot
eff_portfolio(mean_returns(shrink=0.1), cov_returns(shrink = 0.2), T, 3, 0.01, NULL) %>% performance_plot
eff_portfolio(mean_returns(shrink=0.5), cov_returns(shrink = 0.2), T, 3, 0.01, NULL) %>% performance_plot
eff_portfolio(mean_returns(shrink=0.5), cov_returns(shrink = 0.2), T, 3, 0.01, 0.06) %>% performance_plot
eff_portfolio(mean_returns(shrink=0.5), cov_returns(shrink = 0.2), T, 3, 0.01, 0.6) %>% performance_plot
min_variance(cov = cov_returns(lag_adjustment = 3)) %>% performance_plot
eff_portfolio(cov_returns(lag_adjustment = 3), T, 3, 0.01, 0.25) %>% performance_plot
fixed_weights(c(0.25, 0.25, 0.25, 0.25)) %>% performance_plot
eff_portfolio(cov_returns(lag_adjustment = 3), T, 3, 0.01, 0.25) %>% performance_plot
fixed_weights(c(0.25, 0.25, 0.25, 0.25)) %>% performance_plot
eff_portfolio(cov_returns(lag_adjustment = 3), T, 3, 0.01, 0.2501) %>% performance_plot
eff_portfolio(mean(),cov_returns(), T, 3, 0.01, 0.2501) %>% performance_plot
eff_portfolio(mean_returns(),cov_returns(), T, 3, 0.01, 0.2501) %>% performance_plot
eff_portfolio(mean_returns(),cov_returns(), T, 3, 0.01, 0.25) %>% performance_plot
eff_portfolio(mean_returns(),cov_returns(), T, 3, 0.01, 0.2500001) %>% performance_plot
fixed_weights(c(0.25, 0.25, 0.25, 0.25)) %>% performance_plot
fixed_weights(c(0.25, 0.25, 0.25, 0.25)) %>% performance_plot
eff_portfolio(mean_returns(),cov_returns(), T, 3, 0.01, 0.2500001) %>% performance_plot
eff_portfolio(mean_returns(shrink=0.5), cov_returns(lag_adjustment = 3), T, 3, 0.01, 0.5) %>% performance_plot
eff_portfolio(mean = mean_returns(shrink=0.5), cov = cov_returns(lag_adjustment = 3), T, 3, 0.01, 0.5) %>% performance_plot
max_sharpe(cov = cov_returns(lag_adjustment = 3),
mean = mean_returns(shrink = 0.5)) %>% performance_plot
eff_portfolio(mean = mean_returns(shrink=0.5), cov = cov_returns(lag_adjustment = 3), T, 3, 0.01, 0.5) %>% performance_plot
eff_portfolio(mean = mean_returns(shrink=0.5), cov = cov_returns(shrink=0.5), T, 3, 0.01, 0.5) %>% performance_plot
eff_portfolio(mean = mean_returns(shrink=0.5), cov = cov_returns(shrink=0.5), T, 3, 0.01, 0.4) %>% performance_plot
eff_portfolio(mean = mean_returns(shrink=0.5), cov = cov_returns(shrink=0.5), T, 3, 0.01, 0.4) %>% performance_plot
eff_portfolio(mean = mean_returns(shrink=0.5), cov = cov_returns(shrink=0.5), T, 3, 0.01, 0.35) %>% performance_plot
library(PortfolioAnalytics)
install.packages("PortfolioAnalytics")
install.packages("PortfolioAnalytics")
install.packages("PortfolioAnalytics")
install.packages("PortfolioAnalytics")
library(PortfolioAnalytics)
library("PortfolioAnalytics")
library(PortfolioAnalytics)
install.packages("PortfolioAnalytics")
install.packages("PortfolioAnalytics")
installed.packages()
library(PortfolioAnalytics)
c(0,1)
c((0,1),(1,1))
c((0,1)(1,1))
library(PortfolioAnalytics)
source("0-helper.R")
source("1-data.R")
mdat <- matrix(c(1,0,0,0, 0,0,1,0, 0,0,1,0, 0,0,0,1), nrow = 3, ncol = 4)
mdat
black.litterman()
mdat <- matrix(c(1,0,0,0, 0,0,1,0, 0,0,1,0, 0,0,0,1), nrow = 3, ncol = 4)
mdat
mdat <- matrix(c(1,0,0,0, 0,0,1,0, 0,0,1,0, 0,0,0,1), nrow = 4, ncol = 4)
mdat
mdat <- matrix(t(c(1,0,0,0, 0,0,1,0, 0,0,1,0, 0,0,0,1)), nrow = 4, ncol = 4)
mdat
mdat <- t(matrix(c(1,0,0,0, 0,0,1,0, 0,0,1,0, 0,0,0,1), nrow = 4, ncol = 4))
mdat
q <- t(matrix(c(1,0,0,0, 0,0,1,0, 0,1,0,0, 0,0,0,1), nrow = 4, ncol = 4))
Pviews <- c(0.1,0.02,0.03,0.3)
library(PortfolioAnalytics)
source("0-helper.R")
source("1-data.R")
q <- t(matrix(c(1,0,0,0, 0,0,1,0, 0,1,0,0, 0,0,0,1), nrow = 4, ncol = 4))
Pviews <- c(0.1,0.02,0.03,0.3)
black.litterman(returns, Pviews, Mu=NULL, Sigma =NULL, Views = NULL)
Pvies
Pviews
library(PortfolioAnalytics)
source("0-helper.R")
source("1-data.R")
q <- t(matrix(c(1,0,0,0, 0,0,1,0, 0,1,0,0, 0,0,0,1), nrow = 4, ncol = 4))
Pviews <- t(c(0.1,0.02,0.03,0.3))
black.litterman(returns, Pviews, Mu=NULL, Sigma =NULL, Views = NULL)
library(PortfolioAnalytics)
source("0-helper.R")
source("1-data.R")
q <- t(matrix(c(1,0,0,1, 0,0,1,0, 0,1,0,0, 0,0,0,1), nrow = 4, ncol = 4))
Pviews <- t(c(0.1,0.02,0.03,0.3))
black.litterman(returns, Pviews, Mu=NULL, Sigma =NULL, Views = NULL)
library(PortfolioAnalytics)
source("0-helper.R")
source("1-data.R")
q <- t(matrix(c(1,0,0,-1, 0,0,1,0, 0,1,0,0, 0,0,0,1), nrow = 4, ncol = 4))
Pviews <- t(c(0.1,0.02,0.03,0.3))
black.litterman(returns, Pviews, Mu=NULL, Sigma =NULL, Views = NULL)
library(PortfolioAnalytics)
source("0-helper.R")
source("1-data.R")
q <- t(matrix(c(1,0,0,-1, 0,0,1,0, 0,1,0,0, 0,0,0,1), nrow = 4, ncol = 4))
Pviews <- t(c(0.1,0.02,0.03,0.3))
black.litterman(returns, Pviews, Mu=NULL, Sigma =NULL, Views = NULL)
returns
library(PortfolioAnalytics)
source("0-helper.R")
source("1-data.R")
q <- t(matrix(c(1,0,0,-1, 0,0,1,0, 0,1,0,0, 0,0,0,1), nrow = 4, ncol = 4))
Pviews <- t(c(0.1,0.02,0.03,0.3))
black.litterman(returns, Pviews, Mu=NULL, Sigma =NULL, Views = NULL)
q <- t(matrix(c(1,0,0,-1, 0,0,1,0, 0,1,0,0, 0,0,0,1), nrow = 4, ncol = 4))
Pviews <- t(c(0.1,0.02,0.03,0.3))
black.litterman(returns, q, Mu=NULL, Sigma =NULL, Views = Pviews)
fixed_weights(c(1/2, 1/2, 1/2, -1/2)) %>%
compute_kpis %>%
pgfplot("equal")
fixed_weights(c(1/2, 1/2, 1/2, -1/2)) %>%
compute_kpis %>%
pgfplot("equal")
fixed_weights(c(1/2, 1/2, 1/2, -1/2)) %>% performance_plot
fixed_weights(c(1/2, 1/2, 1/2, -1/2)) %>% evaluate_plot
max_sharpe(mean = mean_returns(shrink = 0.5),
cov = cov_returns(shrink = T, lag_adjustment = 3)) %>%
evaluate_model
gg_color_hue <- function(n) {
hues = seq(15, 375, length = n + 1)
hcl(h = hues, l = 65, c = 100)[1:n]
}
# convenience function for ggploting xts objects
plotXTS <- function(xtsObject, title, xlab = "time", ylab = "value", size = 0.5){
d <- data.frame(time = index(xtsObject), value = drop(coredata(xtsObject)))
if (dim(xtsObject)[2]) {
d <- melt(d, id.vars = "time", varnames = names(dimnames(xtsObject)))
}
res_plot <- ggplot(d, aes(time, value)) +
xlab(xlab) +
ylab(ylab) +
scale_colour_hue() +
theme(plot.title = element_text(lineheight = .8, face = "bold"), text = element_text(size = 14))
if (dim(xtsObject)[2] > 1) {
res_plot <- res_plot + geom_line(aes(colour = variable), size = size)
}
else {
res_plot <- res_plot + geom_line(colour = gg_color_hue(1), size = size)
}
if (!missing(title)) {
res_plot + ggtitle(title)
}
else {
res_plot
}
}
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
library(grid)
# Make a list from the ... arguments and plotlist
plots <- c(list(...), plotlist)
numPlots = length(plots)
# If layout is NULL, then use 'cols' to determine layout
if (is.null(layout)) {
# Make the panel
# ncol: Number of columns of plots
# nrow: Number of rows needed, calculated from # of cols
layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
ncol = cols, nrow = ceiling(numPlots/cols))
}
if (numPlots == 1) {
print(plots[[1]])
} else {
# Set up the page
grid.newpage()
pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))
# Make each plot, in the correct location
for (i in 1:numPlots) {
# Get the i,j matrix positions of the regions that contain this subplot
matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))
print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
layout.pos.col = matchidx$col))
}
}
}
plotTable <- function(object, name){
if (is.xts(object)) {
object <- data.frame(time = index(object), value = drop(coredata(object)))
}
path <- paste("report/plot-data/", name, ".txt", sep = "")
write.table(object, path, sep = " ", row.names = F, quote = F, na = "nan")
}
xts2df <- function(xts) {
stopifnot(is.xts(xts))
data.frame(time = index(xts), drop(coredata(xts)))
}
df2xts <- function(df) {
stopifnot(is.data.frame(df))
xts(df[,("time" != colnames(df))],df[,("time" == colnames(df))])
}
ones <- function(num) {
rep.int(1, num)
}
zeros <- function(num) {
rep.int(0, num)
}
library(magrittr)
library(quantmod)
library(Quandl)
library(readxl)
library(lubridate)
Sys.setenv(TZ = "UTC")
# -- Indices -------------------
# getSymbols(c("^GDAXI","^DJI","^N225","VXX"),from="1995-01-01")
# -- EURIBOR -------------------
### no  euribor <- Quandl("ECB/RTD_M_S0_N_C_EUR3M_E")
# euribor <- Quandl("BOF/QS_D_IEUTIO3M")
# euribor <- xts(euribor[,-1]/100,euribor[,1])
# -- Factors -------------------
# factors <- read.csv("data/factors.csv")
# factors$X %<>% parse_date_time("%Y%m%d")
# factors <- xts(factors[,-1]/100,factors[,1])["1995/"]
# -- FX -------------------
# eurusd_0 <- getFX("EUR/USD", from = "2008-01-01", to = "2011-01-01", auto.assign = F)
# eurusd_1 <- getFX("EUR/USD", from = "2011-01-02", auto.assign = F)
# eurusd <- rbind(eurusd_0, eurusd_1)
#
# eurjpy_0 <- getFX("EUR/JPY", from = "2008-01-01", to = "2011-01-01", auto.assign = F)
# eurjpy_1 <- getFX("EUR/JPY", from = "2011-01-02", auto.assign = F)
# eurjpy <- rbind(eurjpy_0, eurjpy_1)
#
# fx <- merge.xts(eurusd, eurjpy)
# saveRDS(list(GDAXI=GDAXI, DJI=DJI, N225=N225, VXX=VXX, euribor=euribor, factors=factors, fx=fx),"data/assets")
assets <- readRDS("data/assets")
GDAXI <- assets[["GDAXI"]][,"GDAXI.Adjusted"]
DJI <- assets[["DJI"]][,"DJI.Adjusted"]
N225 <- assets[["N225"]][,"N225.Adjusted"]
VXX <- assets[["VXX"]][,"VXX.Adjusted"]
euribor <- assets[["euribor"]]/252
factors <- assets[["factors"]]
fx <- assets[["fx"]]
assets <- merge.xts(GDAXI, DJI, N225, VXX)["2009-01-30/"] %>% na.locf
colnames(assets) <- c("DAX", "Dow Jones", "Nikkei", "VIX")
asset_returns <- assets %>% ROC(type = "discrete")
returns <- asset_returns["2009-02-02/"] %>% na.omit
colnames(returns) <- c("DAX", "Dow Jones", "Nikkei", "VIX")
euribor <- euribor["2009-02-02/"] %>% na.omit
factors <- factors["2009-02-02/"] %>% na.omit
fx <- fx["2009-02-02/"]
rm(list = c("GDAXI", "DJI", "N225", "VXX", "asset_returns"))
message("> Imported data ---------------")
#apply(assets,2,function(x)x/drop(coredata(x[1]))*100) %>% as.xts %>% plotTable("assets")
max_sharpe(mean = mean_returns(shrink = 0.5),
cov = cov_returns(shrink = T, lag_adjustment = 3)) %>%
evaluate_model
cov.shrinl
cov.shrink
eff_portfolio(mean = mean_returns(shrink=0.5), cov = cov_returns(shrink=0.5), T, 3, 0.01, 0.4) %>% performance_plot
pgfplot("equal")
fixed_weights(c(1/2, 1/2, 1/2, -1/2)) %>%
compute_kpis %>%
pgfplot("equal")
min_variance(cov = cov_returns(shrink = T, lag_adjustment = 3)) %>% performance_plot
max_sharpe() %>% pgfplot("max_sharpe")
black.litterman(returns, q, Mu=NULL, Sigma =NULL, Views = Pviews)
source("0-helper.R")
source("1-data.R")
q <- t(matrix(c(1,0,0,-1, 0,0,1,0, 0,1,0,0, 0,0,0,1), nrow = 4, ncol = 4))
Pviews <- t(c(0.1,0.02,0.03,0.3))
black.litterman(returns, q, Mu=NULL, Sigma =NULL, Views = Pviews)
